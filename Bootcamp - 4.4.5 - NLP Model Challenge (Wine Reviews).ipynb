{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('winemag.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = temp\n",
    "X_train, X_test = train_test_split(X, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ['Unnamed: 0', 'region_1', 'region_2', 'designation','taster_twitter_handle', 'province', \n",
    "          'title', 'winery','variety']\n",
    "df = df.drop(remove,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     country                                        description  points  \\\n",
      "0  Argentina  Like almost every wine in Trapiche's single-vi...      93   \n",
      "1         US  From Paso Robles's warmer eastside, this wine ...      92   \n",
      "2      Italy  This is a bright and perky red wine with well-...      89   \n",
      "3         US  This wine is a blend of 40% each Mourvèdre and...      88   \n",
      "4     Israel  Light cassis and black currant aromas softly a...      84   \n",
      "\n",
      "   price        taster_name  \n",
      "0   50.0  Michael Schachner  \n",
      "1   38.0      Matt Kettmann  \n",
      "2   25.0                NaN  \n",
      "3   20.0   Sean P. Sullivan  \n",
      "4   22.0      Lauren Buzzeo  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill NA of price with average price\n",
    "df['price'].fillna((df['price'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all other rows with country as NA.\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--', '', text)\n",
    "    text = re.sub('[\\[].*?![\\]]', \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartile(value):\n",
    "    if value > 91:\n",
    "        return 1\n",
    "    elif value > 88:\n",
    "        return 2\n",
    "    elif value > 86:\n",
    "        return 3\n",
    "    elif value > 79:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quartile'] = df['points'].apply(quartile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove2 = ['country','price','points','taster_name']\n",
    "df = df.drop(remove2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description  quartile\n",
      "0  Like almost every wine in Trapiche's single-vi...         1\n",
      "1  From Paso Robles's warmer eastside, this wine ...         1\n",
      "3  This wine is a blend of 40% each Mourvèdre and...         3\n",
      "4  Light cassis and black currant aromas softly a...         4\n",
      "6  Concentrated flavors and a richly tannic textu...         2\n"
     ]
    }
   ],
   "source": [
    "df.dtypes\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "for i in range(1,5):\n",
    "    qtemp = df[df['quartile']==i]\n",
    "    qtemp = \" \\n\".join(qtemp['description'])\n",
    "    q.append(qtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df[df['quartile']==1]\n",
    "q1=\" \\n\".join(q1['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = df[df['quartile']==2]\n",
    "q2=\" \\n\".join(q2['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = df[df['quartile']==3]\n",
    "q3=\" \\n\".join(q3['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4 = df[df['quartile']==4]\n",
    "q4=\" \\n\".join(q4['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_doc = nlp(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_doc = nlp(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_doc = nlp(q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_doc = nlp(q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Like, almost, every, wine, in, Trapiche, 's, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(This, feels, layered, and, plush, ,, while, f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Drink, through, 2018, ., \\n)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(From, Paso, Robles, 's, warmer, eastside, ,, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(It, 's, immediately, delicious, once, sipped,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  (Like, almost, every, wine, in, Trapiche, 's, ...  1\n",
       "1  (This, feels, layered, and, plush, ,, while, f...  1\n",
       "2                      (Drink, through, 2018, ., \\n)  1\n",
       "3  (From, Paso, Robles, 's, warmer, eastside, ,, ...  1\n",
       "4  (It, 's, immediately, delicious, once, sipped,...  1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group into sentences\n",
    "q1_sents = [[sent, \"1\"] for sent in q1_doc.sents]\n",
    "q2_sents = [[sent, '2'] for sent in q2_doc.sents]\n",
    "q3_sents = [[sent, \"3\"] for sent in q3_doc.sents]\n",
    "q4_sents = [[sent, '4'] for sent in q4_doc.sents]\n",
    "\n",
    "#Combine the sentences from the 4 quartiles into one df.\n",
    "sentences = pd.DataFrame(q1_sents + q2_sents + q3_sents + q4_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0  1  sentence_length\n",
      "0  (Like, almost, every, wine, in, Trapiche, 's, ...  1               33\n",
      "1  (This, feels, layered, and, plush, ,, while, f...  1               27\n",
      "2                      (Drink, through, 2018, ., \\n)  1                5\n",
      "3  (From, Paso, Robles, 's, warmer, eastside, ,, ...  1               23\n",
      "4  (It, 's, immediately, delicious, once, sipped,...  1               31\n"
     ]
    }
   ],
   "source": [
    "sentences['sentence_length']=sentences[0].str.len()\n",
    "print(sentences.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Utility function to create a list of the 300 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(300)]\n",
    "#item 0 is the word, item 1 is the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a df with features for each word in our common word set.\n",
    "#Each value is the count of the times the word appears.\n",
    "#BOW is bag of words\n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df.loc[:, 'punctuation_length'] = 0\n",
    "    df['quartile'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    df.loc[:, 'unique_words'] = 0\n",
    "    #loc you use the column name, iloc you use index (column number)\n",
    "    #: means all rows. columns within common_words would be 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "\n",
    "        example_words = [token.lemma_\n",
    "                        for token in sentence \n",
    "                        if (not token.is_punct)]       \n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        puncts = [token for token in sentence if (token.is_punct)]\n",
    "        df.loc[i,'punctuation_length'] += len(puncts)\n",
    "        \n",
    "        #Populate row with unique_words\n",
    "        unique_words = [token for token in example_words]\n",
    "        df.loc[i, 'unique_words'] += len(unique_words)\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1words = bag_of_words(q1_doc)\n",
    "q2words = bag_of_words(q2_doc)\n",
    "q3words = bag_of_words(q3_doc)\n",
    "q4words = bag_of_words(q4_doc)\n",
    "common_words = set(q1words + q2words + q3words + q4words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 1000\n",
      "Processing row 2000\n",
      "Processing row 3000\n",
      "Processing row 4000\n",
      "Processing row 5000\n",
      "Processing row 6000\n",
      "Processing row 7000\n",
      "Processing row 8000\n",
      "Processing row 9000\n",
      "Processing row 10000\n",
      "Processing row 11000\n",
      "Processing row 12000\n",
      "Processing row 13000\n",
      "Processing row 14000\n",
      "Processing row 15000\n",
      "Processing row 16000\n",
      "Processing row 17000\n",
      "Processing row 18000\n",
      "Processing row 19000\n",
      "Processing row 20000\n",
      "Processing row 21000\n",
      "Processing row 22000\n",
      "Processing row 23000\n",
      "Processing row 24000\n",
      "Processing row 25000\n",
      "Processing row 26000\n",
      "Processing row 27000\n",
      "Processing row 28000\n",
      "Processing row 29000\n",
      "Processing row 30000\n",
      "Processing row 31000\n",
      "Processing row 32000\n",
      "Processing row 33000\n",
      "Processing row 34000\n",
      "Processing row 35000\n",
      "Processing row 36000\n",
      "Processing row 37000\n",
      "Processing row 38000\n",
      "Processing row 39000\n",
      "Processing row 40000\n",
      "Processing row 41000\n",
      "Processing row 42000\n",
      "Processing row 43000\n",
      "Processing row 44000\n",
      "Processing row 45000\n",
      "Processing row 46000\n",
      "Processing row 47000\n",
      "Processing row 48000\n",
      "Processing row 49000\n",
      "Processing row 50000\n",
      "Processing row 51000\n",
      "Processing row 52000\n",
      "Processing row 53000\n",
      "Processing row 54000\n",
      "Processing row 55000\n",
      "Processing row 56000\n",
      "Processing row 57000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bold</th>\n",
       "      <th>flat</th>\n",
       "      <th>winery</th>\n",
       "      <th>make</th>\n",
       "      <th>good</th>\n",
       "      <th>franc</th>\n",
       "      <th>basic</th>\n",
       "      <th>candy</th>\n",
       "      <th>acid</th>\n",
       "      <th>banana</th>\n",
       "      <th>...</th>\n",
       "      <th>prune</th>\n",
       "      <th>coffee</th>\n",
       "      <th>attractive</th>\n",
       "      <th>pinot</th>\n",
       "      <th>focus</th>\n",
       "      <th>burn</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>punctuation_length</th>\n",
       "      <th>quartile</th>\n",
       "      <th>unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Like, almost, every, wine, in, Trapiche, 's, ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(This, feels, layered, and, plush, ,, while, f...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Drink, through, 2018, ., \\n)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(From, Paso, Robles, 's, warmer, eastside, ,, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(It, 's, immediately, delicious, once, sipped,...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 425 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bold  flat  winery  make  good  franc  basic  candy  acid  banana  \\\n",
       "0     0     0       0     0     0      0      0      0     0       0   \n",
       "1     0     0       0     0     0      0      0      0     0       0   \n",
       "2     0     0       0     0     0      0      0      0     0       0   \n",
       "3     0     0       0     0     0      0      0      0     0       0   \n",
       "4     0     0       0     0     0      0      0      0     0       0   \n",
       "\n",
       "       ...       prune  coffee  attractive  pinot  focus  burn  \\\n",
       "0      ...           0       0           0      0      0     0   \n",
       "1      ...           0       1           0      0      0     0   \n",
       "2      ...           0       0           0      0      0     0   \n",
       "3      ...           0       0           0      0      0     0   \n",
       "4      ...           0       0           0      0      0     0   \n",
       "\n",
       "                                       text_sentence  punctuation_length  \\\n",
       "0  (Like, almost, every, wine, in, Trapiche, 's, ...                   6   \n",
       "1  (This, feels, layered, and, plush, ,, while, f...                   4   \n",
       "2                      (Drink, through, 2018, ., \\n)                   1   \n",
       "3  (From, Paso, Robles, 's, warmer, eastside, ,, ...                   3   \n",
       "4  (It, 's, immediately, delicious, once, sipped,...                   5   \n",
       "\n",
       "   quartile  unique_words  \n",
       "0         1            27  \n",
       "1         1            23  \n",
       "2         1             4  \n",
       "3         1            20  \n",
       "4         1            26  \n",
       "\n",
       "[5 rows x 425 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = bow_features(sentences,common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat the number of words in that sentence into the df.\n",
    "word_counts = pd.concat([word_counts, sentences['sentence_length']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['previous_length'] = None\n",
    "\n",
    "for i in range(1,word_counts.shape[0]):\n",
    "    word_counts.loc[i,'previous_length'] = word_counts.loc[i-1,'sentence_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['diff'] = (word_counts.quartile.ne(word_counts.quartile.shift())).astype(int)\n",
    "word_counts.loc[word_counts['diff'] == 1, 'previous_length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['next_length'] = None\n",
    "for i in range(0,word_counts.shape[-1]):\n",
    "    word_counts.loc[i,'next_length'] = word_counts.loc[i+1,'sentence_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['diff2'] = (word_counts.quartile.ne(word_counts.quartile.shift(-1))).astype(int)\n",
    "word_counts.loc[word_counts['diff2'] == 1, 'next_length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['previous_length'] = word_counts['previous_length'].fillna(word_counts['previous_length'].mean())\n",
    "word_counts['next_length'] = word_counts['next_length'].fillna(word_counts['next_length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = word_counts['quartile']\n",
    "X = np.array(word_counts.drop(['text_sentence','quartile','diff','diff2'],1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score 0.95700409704\n",
      "\n",
      "Test set score 0.381205551336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.38534565,  0.37645637,  0.3866402 ,  0.3813552 ,  0.38340672])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying random forest\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score', rfc.score(X_test, y_test))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(rfc, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43446, 426) (43446,)\n",
      "Training set score 0.451848271417\n",
      "\n",
      "Test set score 0.427673824484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.43281263,  0.42616726,  0.43557435,  0.4246871 ,  0.42415609])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score', lr.score(X_train, y_train))\n",
    "print('\\nTest set score', lr.score(X_test, y_test))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(lr, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random forest shows major overfitting of data. Seems like words do not seem to be good predictor of which quartile \n",
    "the wine would belong in as it only shows ~40% accuracy if we were to use Quartile as a target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Running the Tfidf Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(word_counts, test_size=0.25, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "                            stop_words='english', \n",
    "                            lowercase=True, #convert everything to lower case\n",
    "                            use_idf=True, #use inverse document frequencies in our weighting\n",
    "                            norm=u'l2', #applies a correction factor so short and long paragraphs are treated equally\n",
    "                            smooth_idf=True, #adds 1 to all document frequencies, prevents divide by 0 errors\n",
    "                            ngram_range=(0,3),\n",
    "                            analyzer='word'\n",
    "                           )\n",
    "\n",
    "#applying the vectorizer\n",
    "word_counts_tfidf = vectorizer.fit_transform(word_counts)\n",
    "print('Number of features: %d' % word_counts_tfidf.get_shape()[1])\n",
    "\n",
    "#Split into train and test.\n",
    "X_train_tfidf, X_test_tfidf = train_test_split(word_counts_tfidf, test_size=0.25, random_state=42)\n",
    "#Reshape the vectorizer\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr() #Return a copy of this matrix in Compressed Sparse Row format\n",
    "\n",
    "#Number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "#for each paragraph, list the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 50.1021083294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD #Singular Value Decomposition\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Reduce the feature space to 150\n",
    "svd = TruncatedSVD(150)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False)) #LSA is latent semantic analysis\n",
    "\n",
    "#Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "\n",
    "variance_explained = svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print('Percent variance captured by all components:', total_variance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze what sorts of paragraphs our solution considers similar, for the first five identified topics.\n",
    "paras_by_component = pd.DataFrame(X_train_lsa, index=X_train)\n",
    "\n",
    "for i in range(5):\n",
    "    print('Component {}'.format(i))\n",
    "print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
